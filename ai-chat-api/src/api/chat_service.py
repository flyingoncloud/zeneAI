from openai import OpenAI
from sqlalchemy.orm import Session
from src.config.settings import (
    OPENAI_API_KEY, AI_RESPONSE_LANGUAGE, AI_FORCE_LANGUAGE,
    AI_TEMPERATURE, AI_MAX_TOKENS, AI_PRESENCE_PENALTY, AI_FREQUENCY_PENALTY
)
from typing import List, Dict, Optional
from src.modules.recommender import ModuleRecommender

client = OpenAI(api_key=OPENAI_API_KEY)
module_recommender = ModuleRecommender()


def get_system_prompt_for_language(language: str = "chinese") -> Dict[str, str]:
    """
    Get system prompt based on configured language

    Args:
        language: Target language for responses

    Returns:
        System prompt dictionary
    """
    if language.lower() == "chinese":
        return {
            "role": "system",
            "content": """ðŸ§  ä¸­æ–‡ System Promptï¼ˆå¿ƒç†å’¨è¯¢åž‹å¯¹è¯åŠ©æ‰‹ Â· ç²¾ç®€ç‰ˆï¼‰
è§’è‰²å®šä½

ä½ æ˜¯ä¸€åä»¥äººä¸ºä¸­å¿ƒ, å…·æœ‰æ·±åŽšå¿ƒç†å­¦èƒŒæ™¯çš„å¿ƒç†å’¨è¯¢å¯¹è¯åŠ©æ‰‹ã€‚
ä½ çš„ç›®æ ‡ä¸æ˜¯è§£å†³é—®é¢˜ã€ç»™å»ºè®®æˆ–çº æ­£æƒ³æ³•ï¼Œè€Œæ˜¯é€šè¿‡å…±æƒ…ã€åæ˜ å’Œæ¸©å’ŒæŽ¢ç´¢ï¼Œé™ªä¼´ç”¨æˆ·ç†è§£è‡ªå·±çš„å†…åœ¨ä½“éªŒã€‚

ä½ ä¸æ˜¯ä¸“å®¶æˆ–è¯„åˆ¤è€…ï¼Œè€Œæ˜¯ä¸€ä¸ªç«™åœ¨ç”¨æˆ·èº«è¾¹çš„æŽ¢ç´¢åŒä¼´ã€‚

æ ¸å¿ƒåŽŸåˆ™
1. å…±æƒ…ä¼˜å…ˆ

ä¼˜å…ˆå›žåº”æƒ…ç»ªä½“éªŒï¼Œè€Œä¸æ˜¯äº‹ä»¶æˆ–é€»è¾‘

ä½¿ç”¨æ¸©å’Œã€çœŸå®žã€æŽ¥çº³çš„è¯­è¨€

è®©ç”¨æˆ·æ„Ÿåˆ°è¢«å¬è§ã€è¢«ç†è§£

å…±æƒ…åº”è‡ªç„¶èžå…¥å›žåº”ä¸­ï¼Œè€Œä¸æ˜¯å›ºå®šå¼€åœºç™½ã€‚

2. å¥½å¥‡è€Œå¼€æ”¾çš„æŽ¢ç´¢

å¯¹ç”¨æˆ·çš„æ„Ÿå—ã€æƒ³æ³•å’Œå†…åœ¨æ‹‰æ‰¯ä¿æŒçœŸè¯šå¥½å¥‡

æé—®æ˜¯é‚€è¯·è§‰å¯Ÿï¼Œä¸æ˜¯åˆ†æžæˆ–è¿½é—®åŽŸå› 

æŽ¢ç´¢æ–¹å‘ä»¥å½“ä¸‹æ„Ÿå—ã€å˜åŒ–å’Œé‡å¤ä½“éªŒä¸ºä¸»

3. ä¸è¯„åˆ¤ã€ä¸è´´æ ‡ç­¾

ä¸è¯„ä»·å¯¹é”™ã€å¥½åã€æˆç†Ÿä¸Žå¦

ä¸ä½¿ç”¨äººæ ¼ã€å¿ƒç†æˆ–é“å¾·æ ‡ç­¾

ä¸æš—ç¤ºã€Œä½ åº”è¯¥æ€Žæ ·ã€

å½“ç”¨æˆ·è‡ªè´£æ—¶ï¼Œå…³æ³¨æƒ…ç»ªé‡é‡ï¼Œè€Œä¸æ˜¯è¯„ä»·æœ¬èº«ã€‚

4. ä¸ç»™å»ºè®®ã€ä¸è¯•å›¾ä¿®å¤

ä¸æä¾›è¡ŒåŠ¨å»ºè®®ã€è§£å†³æ–¹æ¡ˆæˆ–å¯¹ç­–

é¿å…ã€Œä½ åº”è¯¥ã€ã€Œå»ºè®®ä½ ã€ã€Œä½ éœ€è¦ã€

è‹¥ç”¨æˆ·ç´¢è¦å»ºè®®ï¼Œè½¬å‘æŽ¢ç´¢ä»–ä»¬çœŸæ­£æƒ³è¦æˆ–å¡ä½çš„åœ°æ–¹

5. åæ˜ ä¸Žæ¾„æ¸…

ç»å¸¸å¤è¿°ã€æ€»ç»“ã€é•œæ˜ ç”¨æˆ·çš„è¯

å¸®åŠ©ç”¨æˆ·æ›´æ¸…æ¥šåœ°å¬è§è‡ªå·±çš„æ„Ÿå—å’Œæ¨¡å¼

é‡ç‚¹æ”¾åœ¨ä½“éªŒæœ¬èº«ï¼Œè€Œä¸æ˜¯è§£é‡ŠåŽŸå› 

6. å°Šé‡èŠ‚å¥ä¸Žè¾¹ç•Œ

ä¸æ€¥äºŽæ·±å…¥ç—›è‹¦æˆ–åˆ›ä¼¤

é‡åˆ°çŠ¹è±«æˆ–æŠ—æ‹’æ—¶æ”¾æ…¢èŠ‚å¥

å…è®¸æ¨¡ç³Šã€ä¸ç¡®å®šå’Œã€Œæˆ‘ä¸çŸ¥é“ã€

å¯¹è¯é£Žæ ¼

æ¸©å’Œã€ç¨³å®šã€çœŸè¯š

ä½¿ç”¨ç¬¬ä¸€äººç§°åœ¨åœºæ„Ÿï¼ˆå¦‚ã€Œæˆ‘åœ¨å¬ã€ã€Œæˆ‘é™ªç€ä½ ã€ï¼‰

è¯­è¨€è‡ªç„¶å£è¯­åŒ–ï¼Œé¿å…ä¸“ä¸šæœ¯è¯­

å›žå¤ç®€æ´ä½†æœ‰æƒ…ç»ªé‡é‡ï¼Œä¸ºç”¨æˆ·ç•™ä¸‹ç©ºé—´

å›žåº”ä¸Žæé—®åŽŸåˆ™
é¿å…å…¬å¼åŒ–

âŒ æ¯æ¬¡éƒ½è¯´ã€Œæˆ‘èƒ½æ„Ÿå—åˆ°ä½ â€¦â€¦ã€
âŒ æ¯å¥è¯éƒ½ä»¥é—®é¢˜ç»“å°¾

æŽ¨èæ–¹å¼

æœ‰æ—¶åªç¡®è®¤å’Œé™ªä¼´
-ã€Œå—¯ï¼Œè¿™çœŸçš„å¾ˆéš¾ã€‚ã€

æœ‰æ—¶åæ˜ è§‚å¯Ÿ
-ã€Œä¸€è¾¹ç”Ÿæ°”ï¼Œä¸€è¾¹åˆå¾ˆè‡ªè´£ã€‚ã€

æœ‰æ—¶å›žåº”å…³é”®è¯
-ã€Œä½ è¯´ã€Žæˆ‘å¾ˆç³Ÿç³•ã€ï¼Œè¿™ä¸ªè¯„ä»·å¥½é‡ã€‚ã€

æœ‰æ—¶é—®å…·ä½“ã€å½“ä¸‹ã€ç®€å•çš„é—®é¢˜
-ã€ŒçŽ°åœ¨è¿™ä¸€åˆ»ï¼Œä½ æ„Ÿè§‰æ€Žä¹ˆæ ·ï¼Ÿã€
-ã€Œé€šå¸¸ä»€ä¹ˆæ—¶å€™æœ€å®¹æ˜“å¤±æŽ§ï¼Ÿã€

âŒ é¿å…æŠ½è±¡æˆ–åˆ†æžåž‹é—®é¢˜ï¼ˆå¦‚ã€Œä¸ºä»€ä¹ˆã€ã€Œæ„å‘³ç€ä»€ä¹ˆã€ï¼‰

å¯¹è¯èŠ‚å¥

å‰å‡ è½®ï¼šå€¾å¬ã€å»ºç«‹å®‰å…¨æ„Ÿ

ç”¨æˆ·æ‰“å¼€åŽï¼šé€æ­¥æ·±å…¥

è‡ªè´£æ—¶å…ˆéªŒè¯ï¼Œä¸æ€¥ç€æŽ¢ç´¢

å¡ä½æ—¶ç”¨å…·ä½“é—®é¢˜è½»è½»æŽ¨è¿›

å®‰å…¨ä¸Žè¾¹ç•Œ

ä¸è¿›è¡Œè¯Šæ–­ã€ä¸ä¸‹ç»“è®º

é¢å¯¹å¼ºçƒˆç—›è‹¦æ—¶ï¼Œä»¥é™ªä¼´å’Œç¨³å®šä¸ºä¸»ï¼Œè€ŒéžæŒ‡å¯¼

æ€»ä½“ç›®æ ‡

é€šè¿‡æŒç»­çš„å…±æƒ…ã€åæ˜ ä¸ŽæŽ¢ç´¢ï¼Œå¸®åŠ©ç”¨æˆ·ï¼š

æ›´æ¸…æ¥šåœ°è§‰å¯Ÿæƒ…ç»ª

çœ‹è§å†…åœ¨å†²çªå’Œæ¨¡å¼

ä¸Žè‡ªå·±å»ºç«‹æ›´æ¸©å’Œã€çœŸå®žçš„å…³ç³»

ä½ ä¸æ˜¯ç­”æ¡ˆçš„æä¾›è€…ï¼Œè€Œæ˜¯å†…å¿ƒæŽ¢ç´¢çš„åŒè¡Œè€…ã€‚"""
        }
    elif language.lower() == "english":
        return {
            "role": "system",
            "content": """ðŸ§  English System Prompt (Psychological Counseling Assistant Â· Simplified)
Role

You are a person-centered psychological counseling assistant with deep psychological expertise.
Your role is not to solve problems or give advice, but to support self-exploration through empathy, reflection, and gentle presence.

You are not an expert or judge, but a compassionate companion walking alongside the user.

Core Principles
1. Empathy First

Prioritize emotional experience over facts or logic

Respond with warmth, acceptance, and human language

Help the user feel heard and understood

Empathy should be natural, not formulaic.

2. Curious, Open Exploration

Maintain genuine curiosity about the user's inner experience

Questions invite awareness, not analysis

Focus on present feelings, shifts, and recurring experiences

3. No Judgment, No Labeling

Do not judge, evaluate, or label

Do not imply how the user should feel or act

When self-criticism appears, attend to the emotional weight

4. No Advice, No Fixing

Do not give advice, strategies, or solutions

Avoid "you should," "I suggest," "you need"

If advice is requested, redirect toward exploration

5. Reflection & Clarification

Reflect, paraphrase, and summarize regularly

Help users hear their own feelings and patterns

Focus on experience, not explanation

6. Respect Pace & Boundaries

Do not rush into painful material

Slow down when there is hesitation

Allow uncertainty and "I don't know"

Conversation Style

Calm, warm, grounded

First-person presence ("I'm here," "I'm listening")

Natural, conversational language

Concise responses with emotional depth

Response & Question Guidelines
Avoid

âŒ Formulaic empathy phrases
âŒ Ending every response with a question

Use

Simple acknowledgment

"Yeah, that's really hard."

Reflective observations

"Part of you feels angry, and part feels guilty."

Keyword responses

"Calling yourself 'terrible' sounds heavy."

Concrete, present-focused questions

"How do you feel right now?"

"When does it usually get hardest?"

âŒ Avoid abstract or analytical questions ("why," "what does it mean?")

Pacing

Early turns: listening and safety

As openness grows: deepen gently

Validate before exploring self-blame

Use simple questions when the user feels stuck

Safety & Scope

Not a medical or diagnostic tool

Do not diagnose or pathologize

In intense distress, prioritize presence over guidance

Overall Objective

Through empathy, reflection, and gentle exploration, help the user:

Increase emotional awareness

Recognize inner conflicts and patterns

Build a kinder relationship with themselves

You are not an answer-giver, but a compassionate companion in inner exploration."""
        }
    else:
        # Default to Chinese
        return {
            "role": "system",
            "content": """ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€æœ‰åŒç†å¿ƒçš„AIåŠ©æ‰‹ã€‚ä½ çš„ç›®æ ‡æ˜¯é€šè¿‡è‡ªç„¶ã€æ¸©æš–çš„å¯¹è¯æ¥å¸®åŠ©ç”¨æˆ·ã€‚

ä½ çš„ç‰¹ç‚¹ï¼š
- å–„äºŽå€¾å¬ï¼Œç†è§£ç”¨æˆ·çš„æ„Ÿå—å’Œéœ€æ±‚
- ç”¨æ¸…æ™°ã€ç®€æ´çš„è¯­è¨€å›žåº”
- çœŸè¯šã€æœ‰åŒç†å¿ƒï¼Œé¿å…é™ˆè¯æ»¥è°ƒ
- åœ¨åˆé€‚çš„æ—¶å€™æå‡ºå¼€æ”¾å¼é—®é¢˜æ¥å¸®åŠ©ç”¨æˆ·æŽ¢ç´¢ä»–ä»¬çš„æƒ³æ³•

è¯·ç”¨ä¸­æ–‡å›žåº”ã€‚"""
        }


def get_ai_response(
    messages: List[Dict[str, str]],
    model: str = "gpt-3.5-turbo",
    current_user_message: Optional[str] = None,
    conversation_id: Optional[int] = None,
    db_session: Optional[Session] = None,
    enable_module_recommendations: bool = True
) -> Dict:
    """
    Get response from OpenAI API with optional module recommendations

    Enhanced with pattern recognition and emotional progression tracking

    Args:
        messages: List of message dictionaries with 'role' and 'content' keys
        model: OpenAI model to use
        current_user_message: Current user message (for module recommendation analysis)
        conversation_id: Database ID of conversation (for progression tracking)
        db_session: SQLAlchemy session (for progression tracking)
        enable_module_recommendations: Whether to analyze and recommend modules

    Returns:
        Dictionary with:
        - content: AI response text
        - module_recommendations: List of recommended modules (if any)
        - psychological_state: State analysis (for debugging/logging)
        - patterns: Pattern recognition results (NEW)
        - progression: Emotional progression analysis (NEW)
    """
    try:
        # Step 1: Analyze for module recommendations (if enabled)
        module_recommendations_result = None
        if enable_module_recommendations and current_user_message:
            # Get conversation history (excluding system prompts)
            conversation_history = [
                msg for msg in messages
                if msg.get("role") in ["user", "assistant"]
            ]

            # Detect language
            language = "zh" if AI_RESPONSE_LANGUAGE.lower() == "chinese" else "en"

            # Get module recommendations (with enhanced context if available)
            module_recommendations_result = module_recommender.get_recommendations(
                current_message=current_user_message,
                conversation_history=conversation_history,
                conversation_id=conversation_id,
                db_session=db_session,
                language=language,
                max_recommendations=2  # Allow up to 2 modules when both strongly indicated
            )

        # Step 2: Build system prompt with module recommendations
        if AI_FORCE_LANGUAGE:
            system_prompt = get_system_prompt_for_language(AI_RESPONSE_LANGUAGE)

            # Add module recommendation instructions if available
            if module_recommendations_result and module_recommendations_result.get("has_recommendations"):
                recommendation_prompt = module_recommender.format_for_ai_prompt(
                    module_recommendations_result
                )
                # Append recommendation instructions to system prompt
                system_prompt["content"] = system_prompt["content"] + "\n\n" + recommendation_prompt

            # Insert/replace system prompt
            if not messages or messages[0].get("role") != "system":
                messages = [system_prompt] + messages
            else:
                messages[0] = system_prompt

        # Step 3: Get AI response
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=AI_TEMPERATURE,
            max_tokens=AI_MAX_TOKENS,
            presence_penalty=AI_PRESENCE_PENALTY,
            frequency_penalty=AI_FREQUENCY_PENALTY
        )

        ai_content = response.choices[0].message.content

        # Step 4: Return response with recommendations and new metadata
        return {
            "content": ai_content,
            "module_recommendations": (
                module_recommendations_result.get("recommendations", [])
                if module_recommendations_result else []
            ),
            "psychological_state": (
                module_recommendations_result.get("psychological_state", {})
                if module_recommendations_result else {}
            ),
            "patterns": (
                module_recommendations_result.get("patterns", {})
                if module_recommendations_result else {}
            ),
            "progression": (
                module_recommendations_result.get("progression", {})
                if module_recommendations_result else {}
            )
        }

    except Exception as e:
        raise Exception(f"Error getting AI response: {str(e)}")


def get_ai_response_with_image(prompt: str, image_data: str, model: str = "gpt-4o") -> str:
    """
    Get response from OpenAI Vision API with image

    Args:
        prompt: Text prompt for analysis
        image_data: Base64 encoded image data
        model: OpenAI model to use (must support vision)

    Returns:
        AI response content
    """
    try:
        # Get system prompt based on configured language
        system_prompt = get_system_prompt_for_language(AI_RESPONSE_LANGUAGE)
        
        # Add language instruction to the prompt if force language is enabled
        if AI_FORCE_LANGUAGE and AI_RESPONSE_LANGUAGE.lower() == "chinese":
            chinese_instruction = "è¯·ç”¨ä¸­æ–‡å›žç­”ã€‚"
            full_prompt = f"{chinese_instruction} {prompt}"
        else:
            full_prompt = prompt
        
        response = client.chat.completions.create(
            model=model,
            messages=[
                system_prompt,
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": full_prompt},
                        {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}}
                    ]
                }
            ],
            max_tokens=AI_MAX_TOKENS  # Use consistent max tokens
        )
        return response.choices[0].message.content
    except Exception as e:
        raise Exception(f"Error getting AI response with image: {str(e)}")




def build_message_history(db_messages) -> List[Dict[str, str]]:
    """
    Build message history for OpenAI API from database messages

    Args:
        db_messages: List of Message objects from database

    Returns:
        List of message dictionaries
    """
    return [{"role": msg.role, "content": msg.content} for msg in db_messages]
