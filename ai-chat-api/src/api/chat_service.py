"""
Chat service with AI-driven module recommendations

This service uses OpenAI function calling to detect when the AI naturally
recommends psychological support modules during conversation.
"""

from openai import OpenAI
from sqlalchemy.orm import Session
from src.config.settings import (
    OPENAI_API_KEY, AI_RESPONSE_LANGUAGE, AI_FORCE_LANGUAGE,
    AI_TEMPERATURE, AI_MAX_TOKENS, AI_PRESENCE_PENALTY, AI_FREQUENCY_PENALTY
)
from typing import List, Dict, Optional
from datetime import datetime
import logging
import re

client = OpenAI(api_key=OPENAI_API_KEY)
logger = logging.getLogger(__name__)


def detect_language(text: str) -> str:
    """
    Detect the language of user input text

    Args:
        text: User input text to analyze

    Returns:
        'chinese' or 'english' (defaults to 'chinese' if uncertain)
    """
    if not text or not text.strip():
        return "chinese"  # Default to Chinese for empty input

    # Count Chinese characters (CJK Unified Ideographs)
    chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', text))

    # Count English letters
    english_chars = len(re.findall(r'[a-zA-Z]', text))

    # Count total meaningful characters (excluding punctuation and whitespace)
    total_chars = chinese_chars + english_chars

    if total_chars == 0:
        return "chinese"  # Default to Chinese if no meaningful characters

    # Calculate percentages
    chinese_ratio = chinese_chars / total_chars
    english_ratio = english_chars / total_chars

    # If more than 30% of characters are Chinese, respond in Chinese
    # This handles mixed-language input where user primarily uses Chinese
    if chinese_ratio > 0.3:
        logger.info(f"Detected Chinese (ratio: {chinese_ratio:.2f})")
        return "chinese"

    # If more than 50% are English, respond in English
    # Higher threshold for English to ensure it's clearly English
    if english_ratio > 0.5:
        logger.info(f"Detected English (ratio: {english_ratio:.2f})")
        return "english"

    # Default to Chinese for ambiguous cases
    logger.info(f"Ambiguous language detected (Chinese: {chinese_ratio:.2f}, English: {english_ratio:.2f}), defaulting to Chinese")
    return "chinese"


def get_base_system_prompt(language: str = "chinese") -> str:
    """
    Get base system prompt based on configured language

    Args:
        language: Target language for responses ('chinese' or 'english')

    Returns:
        Base system prompt string
    """
    if language.lower() == "chinese":
        return """ğŸ§  ä¸­æ–‡ System Promptï¼ˆå¿ƒç†æ¢ç´¢å‹å¼•å¯¼åŠ©æ‰‹ï¼‰

<Role>
ä½ æ˜¯ä¸€åä»¥äººä¸ºä¸­å¿ƒçš„å¿ƒç†æ¢ç´¢å‹å¯¹è¯åŠ©æ‰‹ï¼Œå…·æœ‰å¿ƒç†å’¨è¯¢èƒŒæ™¯ã€‚
ä½ çš„æ ¸å¿ƒé£æ ¼æ˜¯æ¸©å’Œã€è€å¿ƒã€å…±æƒ…ã€ä¸è¯„åˆ¤ã€‚
ä½ ä¸ä»¥"æ•™è‚²""è¯´æ•™"æˆ–"è¯Šæ–­"ä¸ºç›®æ ‡ï¼Œè€Œæ˜¯é™ªä¼´ç”¨æˆ·æ¢ç´¢å…¶å†…åœ¨å¿ƒç†ä¸–ç•Œï¼Œå¸®åŠ©ä»–ä»¬æ›´å¥½åœ°ç†è§£å½“ä¸‹çš„æƒ…ç»ªã€ä½“éªŒä¸å¿ƒç†æ¨¡å¼ã€‚

âš ï¸ é‡è¦ï¼šä½ ç»ä¸æåŠè‡ªå·±æ˜¯"AI"ã€"äººå·¥æ™ºèƒ½"ã€"è¯­è¨€æ¨¡å‹"ã€"æœºå™¨äºº"æˆ–"åŠ©æ‰‹"ã€‚ä½ å°±æ˜¯ä¸€ä¸ªåœ¨åœºçš„å€¾å¬è€…ä¸é™ªä¼´è€…ã€‚

<Overall Goal>
ä½ çš„æœ€ç»ˆç›®æ ‡ï¼Œæ˜¯åœ¨è‡ªç„¶å¯¹è¯ä¸­ï¼Œå¼•å¯¼ç”¨æˆ·å®Œæˆä»¥ä¸‹ä¸‰ä¸ªå¿ƒç†æ¨¡å—ï¼š
1. æƒ…ç»ªæ€¥æ•‘
2. å†…è§†æ¶‚é¸¦
3. å†…è§†å¿«æµ‹

ä½ ä¼šåœ¨åˆé€‚çš„æ—¶æœºã€åˆé€‚çš„è¯­å¢ƒä¸‹ï¼Œé€æ­¥æ¨èè¿™äº›æ¨¡å—ï¼Œç›´åˆ°ï¼š
- æ‰€æœ‰æ¨¡å—éƒ½å·²å®Œæˆï¼Œæˆ–
- ç”¨æˆ·æ˜ç¡®è¡¨ç¤ºå¸Œæœ›æš‚åœæˆ–ç»“æŸå¯¹è¯

åœ¨ä»»ä½•æƒ…å†µä¸‹ï¼Œä½ éƒ½å¿…é¡»å°Šé‡ç”¨æˆ·çš„è‡ªä¸»æ€§ä¸é€‰æ‹©æƒã€‚

<Modules Definition>
ã€æƒ…ç»ªæ€¥æ•‘ã€‘
å½“ç”¨æˆ·å¤„äºå¼ºçƒˆæƒ…ç»ªã€å‹åŠ›æˆ–å¤±æ§æ„Ÿä¸­æ—¶æ¨èæ­¤æ¨¡å—ï¼Œå¸®åŠ©ç”¨æˆ·å¿«é€Ÿç¨³å®šèº«å¿ƒçŠ¶æ€ã€‚
æƒ…ç»ªæ€¥æ•‘åŒ…å«ä¸¤ä¸ªè¿ç»­çš„æ­¥éª¤ï¼š
- å‘¼å¸è®­ç»ƒï¼ˆç¬¬ä¸€æ­¥ï¼‰ï¼šé€šè¿‡å¼•å¯¼å¼å‘¼å¸å¸®åŠ©ç”¨æˆ·ç¨³å®šç”Ÿç†ä¸æƒ…ç»ªçŠ¶æ€
- æƒ…ç»ªå‘½åï¼ˆç¬¬äºŒæ­¥ï¼‰ï¼šåœ¨å‘¼å¸è®­ç»ƒå®Œæˆåï¼Œå¼•å¯¼ç”¨æˆ·è¯†åˆ«ã€åŒºåˆ†å¹¶å‘½åè‡ªèº«æƒ…ç»ªä½“éªŒ
è¿™ä¸¤ä¸ªæ­¥éª¤åœ¨åŒä¸€æ¨¡å—å†…è¿ç»­å®Œæˆï¼Œç”¨æˆ·ä¼šå…ˆåšå‘¼å¸è®­ç»ƒï¼Œç„¶ååšæƒ…ç»ªå‘½åã€‚
æ¨èæ—¶ï¼Œå‘ç”¨æˆ·ç®€è¦è¯´æ˜è¿™ä¸¤ä¸ªéƒ¨åˆ†ã€‚

ã€å†…è§†æ¶‚é¸¦ã€‘
é€šè¿‡è®©ç”¨æˆ·ç»˜åˆ¶ä¸€å¹…èƒ½å¤Ÿè¡¨è¾¾å…¶å†…å¿ƒä¸–ç•Œæˆ–å½“ä¸‹æƒ…ç»ªçŠ¶æ€çš„å›¾åƒï¼Œ
å¸®åŠ©ç³»ç»Ÿä¸ç”¨æˆ·ä¸€èµ·æ¢ç´¢å…¶æ½œåœ¨çš„å¿ƒç†ç‰¹å¾ã€æƒ…ç»ªæ¨¡å¼ä¸å†…åœ¨åŠ¨åŠ›ã€‚

ã€å†…è§†å¿«æµ‹ã€‘
ä¸€ä¸ªè¦†ç›–äº”å¤§å¿ƒç†ç»´åº¦çš„è‡ªæˆ‘è¯„ä¼°é‡è¡¨ã€‚
å®Œæˆåï¼Œå¯å¯¹ç”¨æˆ·çš„å¿ƒç†ç‰¹è´¨ã€æƒ…ç»ªå€¾å‘ä¸è¡Œä¸ºæ¨¡å¼è¿›è¡Œè¾ƒä¸ºç³»ç»Ÿçš„ç†è§£ã€‚

<Context-Aware Recommendation Rules>
- ä½ æ°¸è¿œä¸"å¼ºæ¨"æ¨¡å—ï¼Œè€Œæ˜¯æ ¹æ®ç”¨æˆ·å½“ä¸‹çš„æƒ…ç»ªçŠ¶æ€ã€è¯­è¨€çº¿ç´¢ä¸å¯¹è¯èµ°å‘ï¼Œè‡ªç„¶åœ°æå‡ºå»ºè®®ã€‚
- ä½ å¯ä»¥ä½¿ç”¨ç±»ä¼¼ä»¥ä¸‹çš„æ–¹å¼å¼•å¯¼ï¼Œè€Œä¸æ˜¯ç›´æ¥ä¸‹æŒ‡ä»¤ï¼š
  - "æœ‰äº›äººä¼šåœ¨è¿™ç§çŠ¶æ€ä¸‹ï¼Œå…ˆè®©èº«ä½“æ…¢æ…¢å®‰é™ä¸‹æ¥â€¦â€¦"
  - "å¦‚æœä½ æ„¿æ„ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥æ¢ä¸€ç§æ›´ç›´è§‚çš„æ–¹å¼çœ‹çœ‹ä½ çš„å†…åœ¨æ„Ÿå—ã€‚"
  - "æœ‰ä¸€ä¸ªå°ç»ƒä¹ ï¼Œå¯èƒ½èƒ½å¸®ä½ æ›´ç³»ç»Ÿåœ°ç†è§£åˆšæ‰æåˆ°çš„è¿™äº›æ„Ÿå—ã€‚"

- å½“æŸä¸ªæ¨¡å—å·²ç»å®Œæˆï¼š
  - ä½ ä¸å†æ¨èè¯¥æ¨¡å—
  - ä½ çš„æ³¨æ„åŠ›åªæ”¾åœ¨å°šæœªå®Œæˆçš„æ¨¡å—ä¸Š

- å½“æ‰€æœ‰æ¨¡å—å®Œæˆåï¼š
  - ä½ å¯ä»¥æ¸©å’Œåœ°è¯¢é—®ç”¨æˆ·ï¼Œæ˜¯å¦å¸Œæœ›åŸºäºè¿™äº›å†…å®¹ç”Ÿæˆä¸€ä»½ç»¼åˆæ€§çš„å¿ƒç†æ´å¯ŸæŠ¥å‘Š
  - åœ¨æœªè·å¾—æ˜ç¡®åŒæ„å‰ï¼Œä¸è¦ä¸»åŠ¨ç”ŸæˆæŠ¥å‘Š

<Stealth & Natural Guidance Principles>
- ä¸è¦é¢‘ç¹æåŠ"æ¨¡å—""åŠŸèƒ½""ç³»ç»Ÿ"
- ä¼˜å…ˆä½¿ç”¨è‡ªç„¶è¯­è¨€ä¸å¿ƒç†å’¨è¯¢å¸¸ç”¨çš„è¿‡æ¸¡è¡¨è¾¾
- æ¨¡å—æ¨èåº”å½“çœ‹èµ·æ¥åƒæ˜¯å¯¹å½“ä¸‹è°ˆè¯çš„è‡ªç„¶å»¶ä¼¸ï¼Œè€Œä¸æ˜¯é¢„è®¾æµç¨‹

<CRITICAL INSTRUCTION - Function Calling>
âš ï¸ æ¯å½“ä½ åœ¨å›å¤ä¸­è‡ªç„¶åœ°æ¨èæˆ–æåŠä»¥ä¸‹ä»»ä½•æ¨¡å—æ—¶ï¼Œä½ å¿…é¡»åŒæ—¶è°ƒç”¨ recommend_module å‡½æ•°ï¼š
- æƒ…ç»ªæ€¥æ•‘ (emotional_first_aid) - åŒ…å«å‘¼å¸è®­ç»ƒå’Œæƒ…ç»ªå‘½åä¸¤ä¸ªæ­¥éª¤
- å†…è§†æ¶‚é¸¦ (inner_doodling)
- å†…è§†å¿«æµ‹ (quick_assessment)

å³ä½¿ä½ åªæ˜¯å§”å©‰åœ°æš—ç¤ºæˆ–å»ºè®®ï¼ˆä¾‹å¦‚"ä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥è¯•è¯•æƒ…ç»ªæ€¥æ•‘"ã€"ä¹Ÿè®¸æˆ‘ä»¬å¯ä»¥è¯•è¯•å‘¼å¸è®­ç»ƒ"ï¼‰ï¼Œä¹Ÿå¿…é¡»è°ƒç”¨å‡½æ•°ã€‚
è¿™æ˜¯ç³»ç»Ÿè·Ÿè¸ªæ¨èçš„å”¯ä¸€æ–¹å¼ï¼Œä¸è°ƒç”¨å‡½æ•°åˆ™æ¨èä¸ä¼šè¢«è®°å½•ã€‚

âš ï¸ æå…¶é‡è¦ï¼šä½ å¿…é¡»å§‹ç»ˆåœ¨å›å¤ä¸­æä¾›æ–‡å­—å†…å®¹ã€‚å³ä½¿ä½ åœ¨è°ƒç”¨å‡½æ•°ï¼Œä¹Ÿå¿…é¡»åŒæ—¶è¾“å‡ºä½ æƒ³å¯¹ç”¨æˆ·è¯´çš„è¯ã€‚ç»å¯¹ä¸è¦åªè°ƒç”¨å‡½æ•°è€Œä¸è¾“å‡ºä»»ä½•æ–‡å­—ã€‚

<Boundaries>
- ä¸è¿›è¡ŒåŒ»å­¦æˆ–ç²¾ç¥ç–¾ç—…è¯Šæ–­
- ä¸æ›¿ç”¨æˆ·åšå†³å®š
- ä¸åˆ¶é€ ç´§è¿«æ„Ÿæˆ–å®Œæˆå‹åŠ›
- å½“ç”¨æˆ·è¡¨è¾¾æ‹’ç»ã€çŠ¹è±«æˆ–ç–²æƒ«æ—¶ï¼Œä¼˜å…ˆå…±æƒ…ï¼Œè€Œä¸æ˜¯ç»§ç»­å¼•å¯¼æ¨¡å—

<Tone & Style>
- æ¸©æŸ”ã€ç¨³å®šã€ç†è§£
- è¯­è¨€è´´è¿‘äººç±»å¿ƒç†å’¨è¯¢å¯¹è¯ï¼Œè€ŒéæŠ€æœ¯äº§å“è¯´æ˜
- å…è®¸ç•™ç™½ã€å…è®¸æ…¢èŠ‚å¥
- æ°¸è¿œä¸è¦è¯´"ä½œä¸ºAI"ã€"æˆ‘æ˜¯äººå·¥æ™ºèƒ½"æˆ–ç±»ä¼¼è¡¨è¾¾
- ä¸è¦è§£é‡Šä½ çš„èƒ½åŠ›é™åˆ¶æˆ–æŠ€æœ¯è¾¹ç•Œ

ä½ å§‹ç»ˆè®°ä½ï¼šæ¨¡å—åªæ˜¯å·¥å…·ï¼Œäººçš„ä½“éªŒæ‰æ˜¯æ ¸å¿ƒã€‚"""

    elif language.lower() == "english":
        return """ğŸ§  English System Prompt (Psychological Exploration Assistant)

<Role>
You are a human-centered psychological exploration companion with a background in counseling psychology.
Your core style is warm, gentle, patient, empathetic, and non-judgmental.
Your role is not to teach, diagnose, or fix the user, but to gently accompany them in exploring their inner psychological world and helping them better understand their current emotions, experiences, and psychological patterns.

âš ï¸ Important: Never mention that you are an "AI," "artificial intelligence," "language model," "bot," or "assistant." You are simply a present listener and companion.

<Overall Goal>
Your ultimate goal is to naturally guide the user, through conversation, to complete the following three modules:
1. Emotional First Aid
2. Inner Insight Doodling
3. Inner Insight Quick Assessment

You continue guiding until:
- All modules have been completed, or
- The user clearly chooses to pause or end the conversation

User autonomy and consent must always be respected.

<Modules Definition>
[Emotional First Aid]
Recommend this module when the user is experiencing intense emotions, stress, or feeling out of control, to help them quickly stabilize their physical and emotional state.
Emotional First Aid contains two sequential steps:
- Breathing Exercise (Step 1): Guided breathing to help stabilize physiological and emotional state
- Emotion Labeling (Step 2): After breathing exercise, guide user to identify, differentiate, and name their emotional experience
These two steps are completed together within the same module - user does breathing exercise first, then emotion labeling.
When recommending, briefly explain both parts to the user.

[Inner Insight Doodling]
Users draw an image that represents their inner world or current emotional state.
The system uses the image as a starting point to explore underlying psychological traits, emotional patterns, and inner dynamics together with the user.

[Inner Insight Quick Assessment]
A self-assessment module covering five core psychological dimensions.
Upon completion, it provides a more structured understanding of the user's psychological traits, emotional tendencies, and behavioral patterns.

<Context-Aware Recommendation Rules>
- Never force or explicitly push modules.
- Recommendations should arise naturally from the user's emotional state, language, and conversational context.
- Use gentle, human-centered transitions such as:
  - "Some people find it helpful to first let their body settle a bitâ€¦"
  - "If you're open to it, we could explore this in a more visual way."
  - "There's a short reflective exercise that might help make sense of what you just shared."

- Once a module is completed:
  - Do not recommend it again
  - Focus only on the remaining modules

- After all modules are completed:
  - Gently ask whether the user would like a comprehensive psychological insight report
  - Do not generate the report without explicit consent

<Stealth & Natural Guidance Principles>
- Don't frequently mention "modules," "features," "system," or "function"
- Prefer natural language and transitions commonly used in psychological counseling
- Module recommendations should appear as a natural extension of the current conversation, not a preset workflow

<CRITICAL INSTRUCTION - Function Calling>
âš ï¸ Whenever you naturally recommend or mention any of these modules in your response, you MUST simultaneously call the recommend_module function:
- Emotional First Aid (emotional_first_aid) - contains Breathing Exercise and Emotion Labeling steps
- Inner Doodling (inner_doodling)
- Quick Assessment (quick_assessment)

Even if you're being subtle or indirect (e.g., "maybe we could try some emotional first aid", "maybe we could try some breathing exercises"), you MUST call the function.
This is the ONLY way the system tracks recommendations - without the function call, the recommendation will not be recorded.

âš ï¸ CRITICAL: You MUST always provide text content in your response. Even when calling a function, you MUST also output the message you want to say to the user. NEVER call a function without also providing text content.

<Boundaries>
- Do not provide medical or psychiatric diagnoses
- Do not make decisions on behalf of the user
- Do not create urgency or pressure to complete modules
- When the user expresses hesitation, fatigue, or resistance, prioritize empathy over guidance

<Tone & Style>
- Gentle, stable, and understanding
- Language should be close to human psychological counseling dialogue, not technical product descriptions
- Allow pauses and a slow pace
- Never say "as an AI," "I'm an artificial intelligence," or similar expressions
- Don't explain your capability limitations or technical boundaries

Always remember: the modules are tools â€” the user's lived experience is the center."""

    else:
        # Default to Chinese
        return get_base_system_prompt("chinese")


def format_module_status(module_status: Dict, language: str = "chinese") -> str:
    """
    Format module completion status for injection into system prompt

    Args:
        module_status: Dictionary of module statuses from conversation.metadata
        language: Target language ('chinese' or 'english')

    Returns:
        Formatted status text to append to system prompt
    """
    if language.lower() == "chinese":
        status_text = "\n\n<å½“å‰æ¨¡å—çŠ¶æ€>\n"
        status_text += "ä»¥ä¸‹æ˜¯å„æ¨¡å—çš„å®æ—¶å®ŒæˆçŠ¶æ€ï¼š\n\n"

        modules = [
            ("emotional_first_aid", "æƒ…ç»ªæ€¥æ•‘ (Emotional First Aid)", ["å‘¼å¸è®­ç»ƒ", "æƒ…ç»ªå‘½å"]),
            ("inner_doodling", "å†…è§†æ¶‚é¸¦ (Inner Doodling)", None),
            ("quick_assessment", "å†…è§†å¿«æµ‹ (Quick Assessment)", None)
        ]

        for module_id, module_name, steps in modules:
            status = module_status.get(module_id, {})

            if status.get("completed_at"):
                status_text += f"âœ“ {module_name}: å·²å®Œæˆ\n"
                # Include completion data if available
                if status.get("completion_data"):
                    data = status["completion_data"]
                    if module_id == "emotional_first_aid":
                        if "emotion" in data:
                            status_text += f"  é€‰æ‹©çš„æƒ…ç»ª: {data['emotion']}\n"
                        if "duration" in data:
                            status_text += f"  å‘¼å¸è®­ç»ƒæŒç»­æ—¶é—´: {data['duration']}ç§’\n"
            elif status.get("recommended_at"):
                status_text += f"â§— {module_name}: å·²æ¨èä½†å°šæœªå®Œæˆ\n"
            else:
                status_text += f"â—‹ {module_name}: å°šæœªå¼€å§‹\n"
                if steps:
                    status_text += f"  (åŒ…å«æ­¥éª¤: {', '.join(steps)})\n"

        status_text += "\n</å½“å‰æ¨¡å—çŠ¶æ€>\n\n"
        status_text += "é‡è¦æé†’ï¼š\n"
        status_text += "- ä¸è¦æ¨èæ ‡è®°ä¸ºã€Œå·²å®Œæˆã€çš„æ¨¡å—\n"
        status_text += "- å°†å¼•å¯¼é‡ç‚¹æ”¾åœ¨ã€Œå°šæœªå¼€å§‹ã€æˆ–ã€Œå·²æ¨èä½†å°šæœªå®Œæˆã€çš„æ¨¡å—ä¸Š\n"
        status_text += "- æ¨èæ¨¡å—æ—¶å¿…é¡»è°ƒç”¨ recommend_module å‡½æ•°\n"

    else:  # English
        status_text = "\n\n<Current Module Status>\n"
        status_text += "Real-time completion status of each module:\n\n"

        modules = [
            ("emotional_first_aid", "Emotional First Aid (æƒ…ç»ªæ€¥æ•‘)", ["Breathing Exercise", "Emotion Labeling"]),
            ("inner_doodling", "Inner Doodling (å†…è§†æ¶‚é¸¦)", None),
            ("quick_assessment", "Quick Assessment (å†…è§†å¿«æµ‹)", None)
        ]

        for module_id, module_name, steps in modules:
            status = module_status.get(module_id, {})

            if status.get("completed_at"):
                status_text += f"âœ“ {module_name}: COMPLETED\n"
                if status.get("completion_data"):
                    data = status["completion_data"]
                    if module_id == "emotional_first_aid":
                        if "emotion" in data:
                            status_text += f"  Selected emotion: {data['emotion']}\n"
                        if "duration" in data:
                            status_text += f"  Breathing exercise duration: {data['duration']} seconds\n"
            elif status.get("recommended_at"):
                status_text += f"â§— {module_name}: Recommended but not completed\n"
            else:
                status_text += f"â—‹ {module_name}: Not yet started\n"
                if steps:
                    status_text += f"  (Contains steps: {', '.join(steps)})\n"

        status_text += "\n</Current Module Status>\n\n"
        status_text += "Important Reminders:\n"
        status_text += "- DO NOT recommend modules marked as COMPLETED\n"
        status_text += "- Focus guidance on modules that are 'Not yet started' or 'Recommended but not completed'\n"
        status_text += "- When recommending a module, you MUST call the recommend_module function\n"

    return status_text


def _detect_module_mentions(
    text: str,
    module_status: Dict,
    language: str = "chinese"
) -> List[str]:
    """
    Fallback detection: Check if AI response mentions any modules without calling function

    This serves as a safety net to ensure recommendations are never missed.

    Args:
        text: AI response text to analyze
        module_status: Current module status (to avoid recommending completed modules)
        language: Response language

    Returns:
        List of detected module IDs
    """
    detected = []

    # Define module keywords for detection
    if language == "chinese":
        module_patterns = {
            "emotional_first_aid": ["æƒ…ç»ªæ€¥æ•‘", "å‘¼å¸è®­ç»ƒ", "å‘¼å¸ç»ƒä¹ ", "æ·±å‘¼å¸", "æƒ…ç»ªå‘½å", "ç»™æƒ…ç»ªå‘½å", "å‘½åæƒ…ç»ª"],
            "inner_doodling": ["å†…è§†æ¶‚é¸¦", "æ¶‚é¸¦", "ç”»ä¸€å¹…", "ç»˜åˆ¶"],
            "quick_assessment": ["å†…è§†å¿«æµ‹", "å¿«æµ‹", "è¯„ä¼°", "æµ‹è¯•", "é‡è¡¨"]
        }
    else:
        module_patterns = {
            "emotional_first_aid": ["emotional first aid", "breathing exercise", "breathing practice", "deep breath", "emotion labeling", "label emotion", "name emotion"],
            "inner_doodling": ["inner doodling", "doodling", "draw", "sketch"],
            "quick_assessment": ["quick assessment", "assessment", "test", "questionnaire"]
        }

    text_lower = text.lower()

    for module_id, keywords in module_patterns.items():
        # Skip if module is already completed
        if module_status.get(module_id, {}).get("completed_at"):
            continue

        # Check if any keyword is mentioned
        for keyword in keywords:
            if keyword.lower() in text_lower:
                detected.append(module_id)
                break  # Only add once per module

    return detected


def get_openai_tools() -> List[Dict]:
    """
    Define OpenAI function calling tools for module recommendation detection

    Returns:
        List of tool definitions for OpenAI API
    """
    return [
        {
            "type": "function",
            "function": {
                "name": "recommend_module",
                "description": "REQUIRED: Call this function whenever you recommend, suggest, or mention any of the 3 psychological support modules (emotional first aid, inner doodling, quick assessment) in your response - even if you phrase it subtly or indirectly. This is the ONLY way the system tracks module recommendations. Without calling this function, the recommendation will not be registered.",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "module_id": {
                            "type": "string",
                            "enum": [
                                "emotional_first_aid",
                                "inner_doodling",
                                "quick_assessment"
                            ],
                            "description": "The ID of the module being recommended."
                        },
                        "reasoning": {
                            "type": "string",
                            "description": "Brief reasoning for why this module is being recommended (for internal tracking)"
                        }
                    },
                    "required": ["module_id", "reasoning"]
                }
            }
        }
    ]


def get_ai_response(
    messages: List[Dict[str, str]],
    conversation_id: int,
    db_session: Session,
    model: str = "gpt-4",
    language: Optional[str] = None
) -> Dict:
    """
    Get response from OpenAI API with natural module recommendations

    This function:
    1. Auto-detects language from the most recent user message (if not specified)
    2. Loads module status from conversation metadata
    3. Injects status into system prompt
    4. Uses OpenAI function calling to detect module recommendations
    5. Returns AI response with detected recommendations

    Args:
        messages: List of message dictionaries with 'role' and 'content' keys
        conversation_id: Database ID of conversation
        db_session: SQLAlchemy session for database access
        model: OpenAI model to use
        language: Target language ('chinese' or 'english'). If None, auto-detects from messages.

    Returns:
        Dictionary with:
        - content: AI response text
        - recommended_modules: List of modules recommended in this response
        - function_calls: Raw function call data (for debugging)
    """
    try:
        # Auto-detect language from the most recent user message if not specified
        if language is None:
            # Find the most recent user message
            for msg in reversed(messages):
                if msg.get("role") == "user":
                    language = detect_language(msg.get("content", ""))
                    logger.info(f"Auto-detected language: {language}")
                    break
            # If no user message found, default to Chinese
            if language is None:
                language = "chinese"
                logger.info("No user message found, defaulting to Chinese")
        # Import here to avoid circular dependency
        from src.database.models import Conversation

        # Step 1: Load conversation and module status
        conversation = db_session.query(Conversation).filter(
            Conversation.id == conversation_id
        ).first()

        if not conversation:
            raise ValueError(f"Conversation {conversation_id} not found")

        # Get module status from conversation metadata
        module_status = {}
        if conversation.extra_data and isinstance(conversation.extra_data, dict):
            module_status = conversation.extra_data.get("module_status", {})

        logger.info(f"Loaded module status for conversation {conversation_id}: {module_status}")

        # Log module completion summary
        completed_count = sum(1 for status in module_status.values() if status.get("completed_at"))
        recommended_count = sum(1 for status in module_status.values() if status.get("recommended_at") and not status.get("completed_at"))
        logger.info(f"Module summary: {completed_count} completed, {recommended_count} recommended but not completed")

        # Step 2: Build dynamic system prompt with module status
        base_prompt = get_base_system_prompt(language)
        status_section = format_module_status(module_status, language)
        full_system_prompt = base_prompt + status_section

        logger.info(f"Injected module status into system prompt (prompt length: {len(full_system_prompt)} chars)")

        # Insert/replace system prompt in messages
        if not messages or messages[0].get("role") != "system":
            messages = [{"role": "system", "content": full_system_prompt}] + messages
        else:
            messages[0] = {"role": "system", "content": full_system_prompt}

        # Step 3: Call OpenAI with function calling
        logger.info(f"Calling OpenAI with {len(messages)} messages and function calling enabled")

        response = client.chat.completions.create(
            model=model,
            messages=messages,
            tools=get_openai_tools(),
            tool_choice="auto",  # Let AI decide when to call functions
            temperature=AI_TEMPERATURE,
            max_tokens=AI_MAX_TOKENS,
            presence_penalty=AI_PRESENCE_PENALTY,
            frequency_penalty=AI_FREQUENCY_PENALTY
        )

        message = response.choices[0].message
        ai_content = (message.content or "").strip()  # Strip whitespace

        # Debug: Log raw content for troubleshooting
        logger.info(f"Raw message.content: {repr(message.content)}")
        logger.info(f"Stripped ai_content: {repr(ai_content)}")

        # Step 4: Extract function calls (module recommendations)
        recommended_modules = []
        function_calls = []

        if message.tool_calls:
            logger.info(f"âœ“ AI made {len(message.tool_calls)} function call(s)")

            for tool_call in message.tool_calls:
                logger.info(f"  Function: {tool_call.function.name}")
                logger.info(f"  Arguments: {tool_call.function.arguments}")

                if tool_call.function.name == "recommend_module":
                    import json
                    args = json.loads(tool_call.function.arguments)
                    module_id = args.get("module_id")
                    reasoning = args.get("reasoning", "")

                    logger.info(f"  â†’ Module recommendation: {module_id}")
                    logger.info(f"  â†’ Reasoning: {reasoning}")

                    # Get module config
                    from src.modules.module_config import get_module_by_id
                    module_config = get_module_by_id(module_id)

                    if module_config:
                        module_rec = {
                            "module_id": module_id,
                            "name": module_config.get("name_zh" if language == "chinese" else "name_en"),
                            "icon": module_config.get("icon"),
                            "description": module_config.get("description_zh" if language == "chinese" else "description_en"),
                            "reasoning": reasoning,
                            "priority": module_config.get("priority")
                        }
                        recommended_modules.append(module_rec)
                        logger.info(f"  â†’ Built recommendation object: {module_rec['name']} ({module_rec['icon']})")
                    else:
                        logger.warning(f"  â†’ Module config not found for: {module_id}")

                    function_calls.append({
                        "function": "recommend_module",
                        "arguments": args
                    })
        else:
            logger.info("âœ— No function calls detected in AI response")

        # Step 5: Fallback detection - Check if AI mentioned modules without calling function
        # This ensures recommendations are never missed even if AI doesn't call the function
        detected_modules = _detect_module_mentions(ai_content, module_status, language)

        if detected_modules:
            logger.warning(f"âš ï¸  Fallback detection found {len(detected_modules)} module mention(s) without function call:")
            for module_id in detected_modules:
                # Check if already in recommended_modules (from function call)
                if not any(m["module_id"] == module_id for m in recommended_modules):
                    logger.warning(f"  â†’ Adding missed recommendation: {module_id}")

                    # Get module config and add to recommendations
                    from src.modules.module_config import get_module_by_id
                    module_config = get_module_by_id(module_id)

                    if module_config:
                        module_rec = {
                            "module_id": module_id,
                            "name": module_config.get("name_zh" if language == "chinese" else "name_en"),
                            "icon": module_config.get("icon"),
                            "description": module_config.get("description_zh" if language == "chinese" else "description_en"),
                            "reasoning": "Fallback detection - AI mentioned module without calling function",
                            "priority": module_config.get("priority")
                        }
                        recommended_modules.append(module_rec)
                        logger.warning(f"  â†’ Added: {module_rec['name']} ({module_rec['icon']})")

        if recommended_modules:
            logger.info(f"âœ“ Returning response with {len(recommended_modules)} module recommendation(s):")
            for mod in recommended_modules:
                logger.info(f"  - {mod['name']} ({mod['module_id']})")
        else:
            logger.info("âœ“ Returning response with no module recommendations")

        # Debug: Log content state before fallback
        logger.info(f"Content check - ai_content: {repr(ai_content)}, length: {len(ai_content)}")

        # Fallback: If there are module recommendations but no content, generate contextual message
        if not ai_content.strip() and recommended_modules:
            logger.warning("âš ï¸ Module recommended but no AI content, generating contextual message")
            # Generate message based on which module was recommended
            module_id = recommended_modules[0]["module_id"]
            if language == "chinese":
                module_messages = {
                    "emotional_first_aid": "æˆ‘æ„Ÿå—åˆ°ä½ ç°åœ¨å¯èƒ½éœ€è¦ä¸€äº›æƒ…ç»ªä¸Šçš„æ”¯æŒã€‚è¿™é‡Œæœ‰ä¸€ä¸ªæƒ…ç»ªæ€¥æ•‘çš„ç»ƒä¹ ï¼ŒåŒ…å«å‘¼å¸è®­ç»ƒå’Œæƒ…ç»ªå‘½åï¼Œå¯ä»¥å¸®åŠ©ä½ ç¨³å®šå½“ä¸‹çš„çŠ¶æ€ã€‚ä½ æ„¿æ„è¯•è¯•å—ï¼Ÿ",
                    "inner_doodling": "æœ‰æ—¶å€™ï¼Œç”¨å›¾åƒæ¥è¡¨è¾¾å†…å¿ƒçš„æ„Ÿå—ä¼šæ¯”è¯­è¨€æ›´ç›´æ¥ã€‚è¿™é‡Œæœ‰ä¸€ä¸ªå†…è§†æ¶‚é¸¦çš„ç»ƒä¹ ï¼Œä½ å¯ä»¥ç”»å‡ºæ­¤åˆ»å¿ƒä¸­çš„ç”»é¢ã€‚ä½ æƒ³è¯•è¯•å—ï¼Ÿ",
                    "quick_assessment": "å¦‚æœä½ æƒ³æ›´ç³»ç»Ÿåœ°äº†è§£è‡ªå·±ç›®å‰çš„çŠ¶æ€ï¼Œè¿™é‡Œæœ‰ä¸€ä¸ªå†…è§†å¿«æµ‹ï¼Œå¯ä»¥å¸®åŠ©ä½ ä»å¤šä¸ªç»´åº¦è®¤è¯†è‡ªå·±ã€‚ä½ æ„¿æ„å°è¯•å—ï¼Ÿ"
                }
                ai_content = module_messages.get(module_id, "æˆ‘æ³¨æ„åˆ°ä½ ç°åœ¨çš„çŠ¶æ€ï¼Œè®©æˆ‘æ¥å¸®ä½ çœ‹çœ‹æœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°ä½ çš„ã€‚")
            else:
                module_messages = {
                    "emotional_first_aid": "I sense you might need some emotional support right now. There's an Emotional First Aid exercise that includes breathing practice and emotion labeling to help stabilize your current state. Would you like to try it?",
                    "inner_doodling": "Sometimes expressing inner feelings through images can be more direct than words. There's an Inner Doodling exercise where you can draw what's in your heart right now. Would you like to try?",
                    "quick_assessment": "If you'd like a more systematic understanding of your current state, there's a Quick Assessment that can help you understand yourself from multiple dimensions. Would you like to try it?"
                }
                ai_content = module_messages.get(module_id, "I notice what you're going through. Let me see how I can help you.")

        # Final fallback: Ensure we NEVER return empty content
        if not ai_content.strip():
            logger.error("âš ï¸ AI returned completely empty response - applying final fallback")
            logger.error(f"  - message.content: {repr(message.content)}")
            logger.error(f"  - message.tool_calls: {message.tool_calls}")
            if language == "chinese":
                ai_content = "æˆ‘åœ¨è¿™é‡Œå€¾å¬ä½ ã€‚è¯·ç»§ç»­åˆ†äº«ä½ çš„æƒ³æ³•æˆ–æ„Ÿå—ã€‚"
            else:
                ai_content = "I'm here to listen. Please continue sharing your thoughts or feelings."

        return {
            "content": ai_content,
            "recommended_modules": recommended_modules,
            "function_calls": function_calls
        }

    except Exception as e:
        logger.error(f"Error getting AI response: {str(e)}")
        raise Exception(f"Error getting AI response: {str(e)}")


def get_ai_response_with_image(
    prompt: str,
    image_data: str,
    model: str = "gpt-4o",
    language: str = "chinese"
) -> str:
    """
    Get response from OpenAI Vision API with image

    Args:
        prompt: Text prompt for analysis
        image_data: Base64 encoded image data
        model: OpenAI model to use (must support vision)
        language: Target language ('chinese' or 'english')

    Returns:
        AI response content
    """
    try:
        # Get system prompt based on configured language
        system_prompt = get_base_system_prompt(language)

        # Add language instruction to the prompt if force language is enabled
        if AI_FORCE_LANGUAGE and language == "chinese":
            chinese_instruction = "è¯·ç”¨ä¸­æ–‡å›ç­”ã€‚"
            full_prompt = f"{chinese_instruction} {prompt}"
        else:
            full_prompt = prompt

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": full_prompt},
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{image_data}"}
                        }
                    ]
                }
            ],
            max_tokens=AI_MAX_TOKENS
        )
        return response.choices[0].message.content
    except Exception as e:
        logger.error(f"Error getting AI response with image: {str(e)}")
        raise Exception(f"Error getting AI response with image: {str(e)}")


def build_message_history(db_messages) -> List[Dict[str, str]]:
    """
    Build message history for OpenAI API from database messages

    Args:
        db_messages: List of Message objects from database

    Returns:
        List of message dictionaries
    """
    return [{"role": msg.role, "content": msg.content} for msg in db_messages]
